defaults:
  - algorithm: pets
  - dynamics_model: gaussian_mlp_ensemble
  - overrides: pets_cartpole
  - action_optimizer: cem

device: "cuda:0"
log_frequency_agent: 1000
save_video: false
debug_mode: false

use_yuda_default: false
add_exp_to_replay_buffer: false
use_policy_buffer_adv_update: false

silent: true
from_end: false
shaky: true
p_tremble: -1
hyirl: false


sac_schedule_lr: false
schedule_sac_ratio: true
sac_schedule:
  start_ratio: 0.5
  mid_ratio: 0.5
  end_ratio: 0.2
  m1: 20_000
  m2: 100_000

eval_frequency: 10000

sac_in_real: false

relabel_samples: true
no_regret: false

model_sample_expert_ratio: 0.5   # sample 50/50 from learner/expert
sac_reset_ratio: 0.5    # reset 100% of the time

train_discriminator: false
train_disc_in_model: false
disc_ensemble: false
disc_ensemble_reduction: "min"
disc_binary_reward: false

n_discs: 7
disc:
  lr: 8e-4
  batch_size: 4096
  freq_train_disc: 10000
  num_updates_per_step: 1
  num_traj_samples: 4

experiment: default
seed: 1

root_dir: "./exp"
hydra:
  run:
    dir: ${root_dir}/${algorithm.name}/${experiment}/${overrides.env}/${now:%m.%d}/${now:%H%M%S}-seed${seed}

  sweep:
    dir: ${root_dir}/${algorithm.name}/${experiment}/${overrides.env}/${now:%m.%d}/${now:%H%M%S}-seed${seed}